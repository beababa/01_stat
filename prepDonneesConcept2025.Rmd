---
title: "Préparation des données pour bases conceptuelles"
output:
  html_document:
    number_sections: yes
    toc: yes
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval  = FALSE)
knitr::opts_chunk$set(echo  = TRUE)
knitr::opts_chunk$set(warning  = FALSE)
``` 



```{r}
library(sf)
library(mapsf)
library(mapview)
```

# Objectif

On extrait pour chaque ville choisie par les étudiants :

- la géométrie de la ville d'après le cog (pb code insee)

- les bv

- les données électorales au bv

- les carreaux 1 km de filosofi

- les iris


# Démarche

Pour les cog, pb Paris et codes postaux




# Base cog


Définition de la liste des villes de base.

Une première définition a été faite mais on reprend la liste.

## Constitution de la liste 

à partir de la feuille d'émargement TD3


```{r}
# recup fichier ville en character pour les codes commençant par zéro
ville <- read.csv("data/TD3Concept.csv", colClasses = "character")
ville <- ville [ville$prénom!="",]
ville <- ville [,2]
# 57 villes différentes 49 uniques 
ville <- unique(na.omit(ville))
# On rajoute Champs sur Marne, Perpignan, Paris 19
ville <- c(ville,"77083", "66136", "75119","93010")
```

53 villes uniques y compris bondy

## Dézippage fichier communes

Une fois suffit...

```{r}
unzip(zipfile = "data/gros/communes-20220101-shp.zip", exdir = "data/gros")
communes <- st_read("data/gros/communes-20220101.shp")
```



## Première extraction


```{r}
fr <- st_read("data/gros/communes-20220101.shp")
# le code INSEE a 5 chiffres y compris le zéro
names(fr)
sel <- fr [fr$insee %in% ville,]
sel$insee
mapview(sel)
# attention une ville en DROM
(pb <- setdiff(ville, sel$insee))
```

11 pb dont codes insee Paris

## Paris

```{r}
Paris <- fr [fr$insee == "75056",]
pbParis <- pb [grep("^75", pb)]
mf_map(Paris)
# téléchargements arrondissements
paris <- st_read("data/arrondissements.geojson")
mf_map(paris, add = T)
parisSel <- paris [paris$c_arinsee %in% pbParis,] 
mf_map(parisSel, add = T, col="red")
mf_label(parisSel, var = "l_ar")
```

6 arrondissements, 12, 16, 17, 18, 19 et 20

Reste pb faux codes insee, grrrr

```{r}
pb <- pb [!(pb  %in% pbParis)]
```

## Codes postaux

retrouver les code insee à partir des cp pour ces 5 communes
utilisation de l'api

```{r}
library(httr)
library(jsonlite)
equiv <- NULL
for (i in pb){
  print(i)
  rqt <- paste0("https://geo.api.gouv.fr/communes?codePostal=",i)
  res <- httr::GET(rqt)
# dans res, on remarque le status à 200, c'est ok. et le format json
  tmp <- fromJSON(rawToChar(res$content))
  equiv <- rbind(equiv, tmp)
}
str(equiv)
equiv$code
selPb <- fr [fr$insee %in% equiv$code,]
selPb <- selPb [,c("insee", "nom")]
```


Reste la commune de Perillos et Ajaccio

```{r}
#66135
# Remplacement par Perpignan
#2A004
selCorse <- fr [fr$insee == "2A004", c("insee", "nom")]
```



## Enregistrement


```{r}
sel <- sel [,c("insee", "nom")]
sel <- rbind (sel, selCorse, selPb)
parisSel <- parisSel [,c("c_arinsee", "l_ar")]
names(parisSel)[1:2] <- c("insee", "nom")
tot <- rbind(parisSel, sel)
st_write(tot, "data/concept.gpkg", "villes", delete_layer = T)
```

51 villes y compris Bondy

dernière vérif

On a 2 villes en moins, mais c'est normal

```{r}
setdiff(ville, tot$insee)
mapview(tot)
```

On veut également récupérer la population des villes (pour comparaison avec votants 
plus loin)

```{r}
equiv <- NULL
insee <- tot$insee
for (i in insee){
  print(i)
  rqt <- paste0("https://geo.api.gouv.fr/communes?code=", i)
  res <- httr::GET(rqt)
# dans res, on remarque le status à 200, c'est ok. et le format json
  tmp <- fromJSON(rawToChar(res$content))
  equiv <- rbind(equiv, tmp)
}
str(equiv)
tot$insee
equiv$code
joint <- merge(tot [,1], equiv, all.x=T, by.x = "insee", by.y="code")
names(joint)
head(joint)
st_write(joint [,-7], "data/concept.gpkg", "ville", delete_layer = T)
dpt <- joint$codeDepartement [!is.na(  joint$codeDepartement )]
dpt <- unique(dpt)
```

## Cartographie France

### Flux IGN dpt

Idée : utiliser les flux ign opur récupérer uniquement les dpt

```{r}
library(httr) # generic webservice package
library(ows4R) # interface pour services ogc
```


```{r}
wfs <- "https://data.geopf.fr/wfs/ows"
# connexion
dpt_client <- WFSClient$new(wfs, serviceVersion = "2.0.0")
```

format R6 OOP paradigme (objet$method())

On repère la couche dpt

```{r}
retour <- dpt_client$getFeatureTypes(pretty = TRUE)
retour [grep("departement", retour$title),]
```


```{r}
url <- parse_url(wfs)
url
url$query <- list(service = "wfs",
                  #version = "2.0.0", # facultative
                  request = "GetFeature",
                  typename = "BDCARTO_V5:departement",
                  outputFormat = "application/json"
                  )
request <- build_url(url)
data <- st_read(request)
# pb Fort de France, on coupe le dpt
which(tot$insee == "97209")
data [grep("^97",data$code_insee),]
data$code_insee [data$code_insee == 972] <- "97"
#data <- data [-c(97,99:101)]
```

```{r}
tot$dep <- substring(tot$insee,1,2)
dpt <- unique(names(table(tot$dep)))
```



```{r}
dptSel <- data [data$code_insee %in% dpt,]
```



## Carto

2 cartos car Fort de France

```{r}
png("img/communeConcept.png")
dptSel1 <- dptSel [dptSel$code_insee == "97",]
mf_init(dptSel1)
mf_map(data, col = "wheat2" , border = NA,add = T)
mf_map(dptSel, add = T, col = "antiquewhite1", border = "wheat")
mf_map(tot, col = "red", border = NA,add = T)
#mf_label(tot, var = "dpt")
mf_layout("Fort de France", credits = "IGN")
dev.off()
```


```{r, eval=FALSE}
png("img/communeConcept2.png")
dptSel2 <- dptSel [dptSel$code_insee != "97",]
mf_init(dptSel2)
mf_map(data, col = "wheat2" , border = NA,add = T)
mf_map(dptSel, add = T, col = "antiquewhite1", border = "wheat")
mf_map(tot, col = "red", border = NA,add = T)
#mf_label(tot, var = "dpt")
mf_layout("Communes choisies par les étudiants sf Martinique", credits = "IGN")
dev.off()
```

![](img/communeConcept.png)
![](img/communeConcept2.png)
Nb de choix par zone

```{r}
table(tot$dep)
```





# BV contours

On teste les contours INSEE et ceux de Rodrigo avec OSM
Le format "pmtiles" s'ouvre très bien mais le fichier a un carroyage.

```{r}
ville <- st_read("data/concept.gpkg", "ville")
```

50 communes

```{r}
# RODRIGO
bv <- st_read("data/gros/bureau.pmtiles")
# le pmtiles pose pb
bv <- st_read("data/gros/bureau-de-vote-insee-reu-openstreetmap.gpkg")
#st_write(bv,"data/gros/bvRodrigo.geojson", append = F)
```
68596


```{r}
#bv <- st_read("data/gros/bv.geojson")
bvBondy <- bv [bv$insee == 93010, c("insee", "nom", "bureau")]
# doublons
bvBondy <- unique(bvBondy)
mapview(bvBondy)
st_write(bvBondy,"data/concept.gpkg", "bvBondy", delete_layer = T)
```



```{r}
bvCourt <- bv [!is.na(bv$bureau), c("insee", "nom", "bureau")]
# 40 303 villes avec plus d'un bureau
# pb des insee arrondissements, on recopie les codes insee des bureaux
bvCourt$insee <- substring(bvCourt$bureau,1,5) 
bvSel <- bvCourt [bvCourt$insee %in% ville$insee,]
```

1756

### Vérification sur Paris


```{r}
bvSelParis <- bvSel [grep("^75", bvSel$insee),]
mapview(bvSelParis, zcol="insee")
```



```{r}
st_write(bvSel, "data/concept.gpkg", "bv", delete_layer = T)
bvSel <- st_read("data/concept.gpkg", "bv")
# pb géométrie : 11 bureaux
bvSelGeometrie <- bvSel [ !st_is_valid(bvSel$geom),]
bvSel <- bvSel [ st_is_valid(bvSel$geom),]
# On ne peut les laisser pour l'agrégation
agg <- aggregate(bvSel [,c("nom", "geom")], list(bvSel$insee, bvSel$nom), length)
names(agg)  [1:3] <- c("insee", "nom", "nbBureaux")
st_write(agg, "data/concept.gpkg", "bvAgg", delete_layer = T)
mapview(agg)
```

1713 bureaux

47 communnes

```{r}
pb <- setdiff(ville$insee, agg$insee)
pb
pb  <- pb [-3]
# Croix Chapeau et Corrèze
bvPb <- bv [bv$insee %in% pb, c("insee", "nom", "bureau")]
bvFin <- rbind(bvSel, bvPb)
```


1747 bureaux

```{r}
st_write(bvFin, "data/concept.gpkg", "bv", delete_layer = T)
bvSel <- st_read("data/concept.gpkg", "bv")
bvSel <- bvSel [ st_is_valid(bvSel$geom),]
```

tous valides !

## Distributions des bureaux

```{r}
vendredi <- read.csv("data/baseGeomatique.csv")
vendredi <- vendredi [vendredi$prénom != "",]
(tab <- sort(table (bvSel$insee)))
nb <- length(names(tab))
png("img/distributionBureauGeomatique.png")
hist(tab, main = paste0("Distribution du nombre de bureaux\n choix communes des ", length(vendredi$prénom)," étudiants"),
     sub = paste0(length(bvSel$insee), " bureaux au total pour ",nb," communes"),
     col = "coral", border = NA,
     xlab = "nb de bureaux",
     ylab = "nb de villes")
dev.off()
```

![](img/distributionBureauGeomatique.png)



## Rapport nb bureaux taille ville


Il faut la population

```{r}
# récupération de la population par ville
df <- as.data.frame(tab) 
df
names(df) <- c("insee", "nbBureaux")
joint <- merge(ville, df, by = "insee")
joint [order(joint$population, decreasing = T),]
joint$population <- joint$population/1000
png("img/bvPOP.png")
plot(joint$nbBureaux, joint$population, col="coral3", pch = 20,
     xlab = "Nb de bureaux", ylab = "population (en milliers)")
# on soustrait les 2 valeurs.
joint <- joint [joint$population < 80,]
modele <- lm(population~nbBureaux, joint)
abline(modele, col = "darkgoldenrod1")
dev.off()
```

![](img/bvPOP.png)

#### Cas particulier

La plus grosse ville c'est Lille

### Lille


```{r}
adresseBV <- read.csv("data/table-bv-reu.csv")
# 50 122
lille <- adresseBV [ grep('^59350',adresseBV$id_brut_insee),]
sort(lille$code)
write.csv (lille, "data/lilleBV.csv")
```


```{r}
lilleContour <- bv [bv$insee == 59350,]
mapview(lilleContour)
```


## Nettoyage

```{r}
bv <- st_read("data/concept.gpkg", "bv")
# 1747
bv2 <- bv [st_is_valid(bv),]
# 1747
bv2 <- st_cast(bv, "POLYGON")
#  4039 Du coup, pl polygone pour un bureau on supprime les petits poly
bv2$aire <- st_area(bv2)/10000
library(units)
bv2$aire <- drop_units(bv2$aire)
bv2 <- bv2 [bv2$aire > 5,]
```

1747, puis 1712 à la fin


Comparaison en terme de nb de bv

```{r}
bvTab <- table(bv$insee)
bv2Tab <- table(bv2$insee)
#On compare les 2 tableaux
sort(bvTab - bv2Tab)
```


Pas mal de perte, il faut regarder dans le détail, on tolère une différence de 3 bureaux.

```{r}
pb <- ville [ville$insee == 97209,]
```

```{r}
bv <- st_read("data/concept.gpkg", "bv")
mart <- bv [bv$nom == 'Fort-de-France',]
png("img/pbFortDeFrance.png")
mf_init(mart)
mf_map(dptSel, type = "base", bg = "cadetblue2", add = T)
#mf_map(fond, col = "antiquewhite1", border = "burlywood2", bg ="cadetblue2", add = T)
mf_map(mart, col = "antiquewhite2", border = "burlywood2", lwd = 2, add = T)
mart$bureau2 <- substring(mart$bureau,7,9)
mf_label(mart, var = "bureau2", cex = 0.5, halo = T)
mf_layout("Fort de France : des bureaux aux numéros discontinus", "opendata REU")
dev.off()
```


![](img/pbFortDeFrance.png)

A voir au cas par cas.

```{r}
st_write(bv2, "data/concept.gpkg", "bvValide", delete_layer = T)
```



1712 bureaux enregistrés


### Nettoyage géométrie

sous Qgis, on passe sous éditeur de sommet, on efface les points
et on passe points to line

```{r}
bvBondy <- bv2 [bv2$insee == '93010',]
bvBondy <- st_union(bvBondy)
enveloppe <- st_convex_hull(bvBondy)
mf_map(enveloppe)
mf_map(bvBondy, add = T)
st_write(bvBondy, "data/concept.gpkg", "aggBondy", delete_layer = T)
st_write(enveloppe, "data/concept.gpkg", "enveloppeBondy", delete_layer = T)
```



nettoyage par la longueur de ligne

```{r}
ligne <- st_cast(bvBondy, "MULTILINESTRING")
ligne <-  st_cast(ligne, "LINESTRING")
ligne <- st_as_sf(ligne)
ligne$longueur <- st_length(ligne)
library(units)
ligne$longueur <- drop_units(ligne$longueur)
ligne <- ligne [ligne$longueur > 5000,]
mf_choro(ligne, var = "longueur")
poly <- st_cast(ligne, "POLYGON")
mf_map(poly)
```


# REU Bureaux de vote

## France entière

REU et adresses bv  en format parquet

```{r}
library(arrow)
adresse <- read_parquet("data/gros/table-adresses-reu.parquet")
adresse <- adresse [adresse$code_commune_ref  %in% ville$insee, ]
# 313 870 adresses
write_parquet(adresse, "data/gros/adresseBVsel.parquet")
adresseBV <- read_parquet("data/gros/table-bv-reu.parquet")
adresseBVSel <- adresseBV [adresseBV$code_commune %in% ville$insee,]
write_parquet(adresseBV, "data/gros/bureauxLoc.csv")
# 1767
```


## Bondy

```{r}
adresseBondy <- adresse [adresse$code_commune_ref == '93010',]
# 5698
```

```{r}
adresseBVBondy <- adresseBV [adresseBV$code_commune == 93010,]
write.csv(adresseBVBondy,"data/bureauxBondyLoc.csv")
```


# Géolocalisation avec la Ban R

```{r}
library(banR)
adresses <- adresseBVBondy [, c("libelle_reu", "voie_reu", "cp_reu", "commune_reu")]
adresses$compil <- paste(adresses$voie_reu, adresses$cp_reu, adresses$commune_reu, sep = " ")
adresses$compil
geoc <- geocode_tbl(tbl = adresses, adresse = compil)
geoc$latitude
mes_adresses_sf <- st_as_sf(geoc, coords = c("longitude", "latitude"), crs = 4326)
bondyLocBureaux <- mes_adresses_sf [, c("libelle_reu", "voie_reu")]
st_write(bondyLocBureaux, "data/bv.gpkg", "bondyLocBureau", delete_layer = T)
```



# Données électorales

### résultats des élections 2022

Comme avec les bv, les points de vigilance sont :

- les arrondissements de Lyon et Marseille

- le DROM Martinique

- les bv unique 

le code bureau est juste un numéro. 

L'objectif serait dés cette étape d'utiliser le code bureau : insee et numéro bureau.


```{r}
bv <- st_read("data/concept.gpkg", "bv")
# 1747
# jointure ville code insee pour les résultats
election2022 <- read.csv("data/gros/p2022-resultats-bureaux-t1.csv", fileEncoding = "UTF-8", header = T, colClasses = "character")
```




```{r}
# Pb pointe à pitre
Martinique <- election2022[grep("Fort-de", election2022$Commune),]
# extraction
election2022Sel <- election2022 [election2022$CodeInsee %in% ville$insee,]
# 2201 lg
length(unique(election2022Sel$CodeInsee))
# 44 - 7 communes
pb <- setdiff(ville$insee, election2022Sel$CodeInsee)
Paris <- election2022 [election2022$CodeInsee == "75056",]
Paris$CodeBdeVote
# 4 chiffres les 2 premiers l'arr les deux derniers le bureau
Paris$arr <- substring(Paris$CodeBdeVote,  1 ,2)
Paris$CodeInsee <- paste0("751", Paris$arr)
# filetre sur les arrondissements
Paris <- Paris [Paris$CodeInsee %in% pb,]
unique(Paris$CodeInsee)
```

Total

```{r}
election2022Sel
Martinique$CodeInsee <- "97209"
# suppression de la colonne arr
Paris <- Paris [, -55]
election <- rbind(election2022Sel, Martinique, Paris)
write.csv(election,"data/election2022.csv", fileEncoding = "UTF-8")
```

2677 lg ou bv (1715 bv)


```{r}
bv$insee
election <- election [election$CodeInsee != "75056",]
write.csv(election, "data/election2022.csv", fileEncoding = "UTF-8")
```

1777


### combien de bv dans le fichier bv ? 17 et 18

cas particuliers à explorer

```{r}
pb <- election2022 [election2022$INSEE_COM %in% c('13055', '69123'),]
lyon <- pb [pb$Libellé.de.la.commune == 'Lyon',]
lyon <- lyon [lyon$Code.du.b.vote %in% c(101:117),]
lyon$INSEE_COM <- '69381'
mars <- pb [pb$Libellé.de.la.commune == 'Marseille',]
mars <- mars [mars$Code.du.b.vote %in% nomBureauMars,]
mars$INSEE_COM <- '13201'
election2022Sel <- rbind(election2022Sel, lyon, mars)
```



pb de la décimale


```{r}
election2022 <- read.csv("data/election2022.csv", 
                         fileEncoding = "UTF-8", dec =",")
str(election2022$CodeBdeVote)
write.csv(election2022,"data/election2022.csv", fileEncoding = "UTF-8")
```



Ce fichier sera joint à celui des bureaux de vote.

# Carreaux

Utilisation des carreaux 1 km 
On fait une base sqlite pour cours SQL par commune

Les carreaux sont ceux du lien du cours :
https://www.insee.fr/fr/statistiques/4176293?sommaire=4176305



```{r}
car <- st_read("data/gros/Filosofi2015_carreaux_1000m_metropole.gpkg")
# 375 en 2154
carMartinique <- st_read("data/gros/Filosofi2015_carreaux_1000m_reg02.gpkg")
mapview(carMartinique)
```

Pb de la projection epsg 5490

```{r}
summary(st_area(carMartinique)/1000000)
carMartinique2154 <- st_transform(carMartinique, 2154)
summary(st_area(carMartinique2154)/1000000)
```

Donc rester dans la projection pour faire les stats. Les
carreaux sont faits pour faire 1km en Martinique

## Test sur Bondy

# Carreaux Filosofi

```{r}
car <- st_read("data/gros/Filosofi2015_carreaux_1000m_metropole.gpkg")
car$id <- rownames(car)
st_crs(car)
st_crs(bv)
bv <- st_transform(car, 2154)
```

## Sélection c


```{r}
inter <- st_intersection(car, bv)
# plutôt intersection avec les villes
ville <- st_read("data/concept.gpkg", "villes")
ville <- st_transform(ville, 2154)
inter <- st_intersection (car, ville)
inter
st_write(inter, "data/concept.gpkg", "carreaux1km", delete_layer = T)
```

export des carrés


```{r}
insee <- ville$insee
for (i in insee) {
  tmp <- inter [inter$insee == i,]
  st_write(tmp,"data/concept.gpkg", paste0("car_", i), delete_layer = T)
}
```

```{r}
car <- st_read("data/gros/carreau.gpkg")
st_layers("data/concept.gpkg")
bv <- st_read("data/concept.gpkg", "bvBondy")
# pour aller plus vite sur l'intersection, on la fait par la ville
bondy <- st_union(st_convex_hull(bv))
interBondy <- st_intersection(car, bondy)
mf_map(interBondy)
```


```{r}
st_crs(interBondy)
st_crs(bv)
# attention on est en 4326 
st_write(interBondy, "data/bondy.sqlite", "inter", delete_layer = T)
st_write(bv, "data/bondy.sqlite", "bv", delete_layer = T)
```


### Inter carreaux / communes

```{r}
ville <- st_read("data/concept.gpkg", "villes")
# nettoyage fichier
names(ville) [2] <- "nom"
ville <- ville [,-3]
# attention test sur 19e / Perpignan et Champs sur marne / Fort de France
# on a recupere le fichier du moodle...
st_crs(car)
summary(st_area(car))
car <- st_transform(car, 2154)
# pas de différence quasiment
st_crs(ville)
ville <- st_transform(ville, 2154)
# filtre sur une seule colonne
inter <- st_intersection(car [, c("Ind")], ville)
```

Fort de France

```{r}
interMartinique <- st_intersection (carMartinique [,"Ind"], ville )
mf_map(inter)
summary(st_area(inter)/10000000)
mf_map(interMartinique)

summary(st_area(interMartinique)/1000000)
inter <- rbind(inter, interMartinique)
```


test sur qls villes pour visualiser les carreaux

```{r}
mf_init(ville [ville$insee == 75117,])
mf_map (inter, add = T, col= NA, border="blue")
mf_map(ville, add=T, border = "red", lwd = 3, col = NA)
mf_label(ville, var = "nom", halo=T, col= "red")
mf_layout("Quelques carreaux", "data.gouv, 2025")
```


prorata du carreau

```{r}
inter$coeff <- round(st_area(inter),0)
# on ramène en base 100
summary(inter$coeff)
```

verif carto


```{r}
mf_map(inter, "coeff", type="choro", add = T, alpha = 0.5, border = NA, leg_pos = NA )
mf_label(inter, "coeff")
```


pb doublons ?


TODO


Enregistrement

```{r}
st_write(inter, "data/concept.gpkg", "inter" , delete_layer = T)
mf_map(inter)
```

1681 carreaux 



