---
title: "Préparation des données pour bases conceptuelles"
output:
  html_document:
    number_sections: yes
    toc: yes
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval  = FALSE)
knitr::opts_chunk$set(echo  = TRUE)
knitr::opts_chunk$set(warning  = FALSE)
``` 



```{r}
library(sf)
library(mapsf)
library(mapview)
```

# Objectif

A partir des données remplies par les étudiants, on met en place le support
des story map.

A savoir :

- une carte avec les différents groupes (nom groupe, étudiant, problèmatique, données)

- une proposition de traitement par groupe à faire en cours


- les carreaux 1 km de filosofi

- les iris





# Base ville


```{r}
st_layers("data/concept.gpkg")
ville <- st_read("data/concept.gpkg", "ville")
mapview(ville)
```



53 villes y compris Bondy

vérifier Perpignan Lourdes et 15e


### Population et nom ville

On veut également récupérer la population des villes (pour comparaison avec votants 
plus loin)


pb sur les cp Paris

La donnée est bizarrement difficile à trouver.
Chat gpt renvoie sur les données santé (ARS), du coup on fait deux jointures


#### ARS

```{r}
data <- read.csv("data/t-popref-com.csv")
data <- data [,c("com_code", "popref_tot")]
tot <- st_read("data/concept.gpkg", "ville")
joint <- merge(tot [,1], data, all.x=T, by.x = "insee", by.y="com_code")
st_write(joint, "data/concept.gpkg", "ville", delete_layer = T)
```


#### Insee

```{r}
equiv <- NULL
insee <- tot$insee
for (i in insee){
  print(i)
  rqt <- paste0("https://geo.api.gouv.fr/communes?code=", i)
  res <- httr::GET(rqt)
# dans res, on remarque le status à 200, c'est ok. et le format json
  tmp <- fromJSON(rawToChar(res$content))
  equiv <- rbind(equiv, tmp)
}
str(equiv)
tot$insee
equiv$code
tot$dep <- substring(tot$insee,1,2)
```

##### Cas Paris

```{r}
equiv[equiv$code == 75056,]
jointParis <- merge(tot [, c("insee", "popref_tot", "dep")], equiv[equiv$code == 75056,], all.x=F, by.y = "codeDepartement", by.x="dep")
jointParis
```

##### Le reste

```{r}
jointReste <- merge(tot [, c("insee", "popref_tot", "dep")], 
                    equiv[equiv$code != 75056,], all.x=F, by.y = "code", by.x="insee")
names(jointReste)
names(jointParis)
nom <- names(jointReste)
nom <- nom [-c(5,9)]
nom
jointParis <- jointParis [,nom]
jointReste <- jointReste [,nom]
joint <- rbind(jointParis, jointReste)
st_write(joint, "data/concept.gpkg", "ville", delete_layer = T)
```




## Cartographie France

### Flux IGN dpt

Idée : utiliser les flux ign opur récupérer uniquement les dpt

```{r}
library(httr) # generic webservice package
library(ows4R) # interface pour services ogc (long à télécharger)
```


chargement couche ville

```{r}
tot <- st_read("data/concept.gpkg", "ville")
```



```{r}
wfs <- "https://data.geopf.fr/wfs/ows"
# connexion
dpt_client <- WFSClient$new(wfs, serviceVersion = "2.0.0")
```

format R6 OOP paradigme (objet$method())

On repère la couche dpt

```{r}
retour <- dpt_client$getFeatureTypes(pretty = TRUE)
retour [grep("departement", retour$title),]
```


```{r}
url <- parse_url(wfs)
url
url$query <- list(service = "wfs",
                  #version = "2.0.0", # facultative
                  request = "GetFeature",
                  typename = "BDCARTO_V5:departement",
                  outputFormat = "application/json"
                  )
request <- build_url(url)
data <- st_read(request)
# pb Fort de France, on coupe le dpt
which(tot$insee == "97209")
data [grep("^97",data$code_insee),]
data$code_insee [data$code_insee == 972] <- "97"
#data <- data [-c(97,99:101)]
```

```{r}
table(tot$dep)
dpt <- unique(names(table(tot$dep)))
```




```{r}
base <- st_read("data/concept.gpkg", "ville")
etudiant <- read.csv("data/td10GroupeDonnee.csv")
etudiant <- etudiant [etudiant$prénom !="",]
inseeEt <- etudiant$code.INSEE..minimum.10.bureaux.
inseeV <- base$insee
erreur <- setdiff(inseeEt, inseeV)
# bcp insee ont disparu
poubelle <- setdiff(inseeV, inseeEt)
```

les erreurs : 29232 2A004 94067 75117

```{r}

correction <- c("29232", "2A004", "94067", "75117")
df <- data.frame(erreur, correction)
df
joint <- merge(etudiant, df, by.x = "code.INSEE..minimum.10.bureaux.", by.y = "erreur", all.x=T)
joint$insee <- ifelse(is.na(joint$correction), joint$code.INSEE..minimum.10.bureaux., joint$correction )
joint [, c("insee", "prénom")]

png("img/communeConcept.png")
dptSel1 <- dptSel [dptSel$code_insee == "97",]
mf_init(dptSel1)
mf_map(data, col = "wheat2" , border = NA,add = T)
mf_map(dptSel, add = T, col = "antiquewhite1", border = "wheat")
mf_map(tot, col = "red", border = NA,add = T)
#mf_label(tot, var = "dpt")
mf_layout("Fort de France", credits = "IGN")
dev.off()
```


```{r, eval=FALSE}
png("img/communeConcept2.png")
dptSel2 <- dptSel [dptSel$code_insee != "97",]
mf_init(dptSel2)
mf_map(data, col = "wheat2" , border = NA,add = T)
mf_map(dptSel, add = T, col = "antiquewhite1", border = "wheat")
mf_map(tot, col = "red", border = NA,add = T)
#mf_label(tot, var = "dpt")
mf_layout("Communes choisies par les étudiants sf Martinique", credits = "IGN")
dev.off()
```

![](img/communeConcept.png)
![](img/communeConcept2.png)
Nb de choix par zone

```{r}
table(tot$dep)
```



```{r}
tot [is.na(tot$codeRegion),]
```


# BV contours

On teste les contours INSEE et ceux de Rodrigo avec OSM
Le format "pmtiles" s'ouvre très bien mais le fichier a un carroyage.

```{r}
ville <- st_read("data/concept.gpkg", "ville")
ville$nom
```


# REU Bureaux de vote

## France entière

REU et adresses bv  en format parquet

```{r}
library(arrow)
adresse <- read_parquet("data/gros/table-adresses-reu.parquet")
adresse <- adresse [adresse$code_commune_ref  %in% ville$insee, ]
# 317 150 adresses
write_parquet(adresse, "data/gros/adresseBVsel.parquet")
adresseBV <- read_parquet("data/gros/table-bv-reu.parquet")
adresseBVSel <- adresseBV [adresseBV$code_commune %in% ville$insee,]
write_parquet(adresseBVSel, "data/gros/bureauxLoc.csv")
# 1779
```


## Bondy

```{r}
adresseBondy <- adresse [adresse$code_commune_ref == '93010',]
# 5698
```

```{r}
adresseBVBondy <- adresseBV [adresseBV$code_commune == 93010,]
write.csv(adresseBVBondy,"data/bureauxBondyLoc.csv")
```


# Géolocalisation avec la Ban R

```{r}
library(banR)
adresses <- adresseBVBondy [, c("libelle_reu", "voie_reu", "cp_reu", "commune_reu")]
adresses$compil <- paste(adresses$voie_reu, adresses$cp_reu, adresses$commune_reu, sep = " ")
adresses$compil
geoc <- geocode_tbl(tbl = adresses, adresse = compil)
geoc$latitude
mes_adresses_sf <- st_as_sf(geoc, coords = c("longitude", "latitude"), crs = 4326)
bondyLocBureaux <- mes_adresses_sf [, c("libelle_reu", "voie_reu")]
st_write(bondyLocBureaux, "data/concept.gpkg", "bondyLocBureau", delete_layer = T)
```



# Données électorales

### résultats des élections 2022

Comme avec les bv, les points de vigilance sont :

- les arrondissements de Paris

- le DROM Martinique (Fort de France)

- les bv unique 

le code bureau est juste un numéro. 

L'objectif serait dés cette étape d'utiliser le code bureau : insee et numéro bureau.

On prend les résultats nettoyés (dans les ressources communautaires)
https://www.data.gouv.fr/fr/datasets/r/25938a29-b571-4c65-87c1-639cff709d95

```{r}
bv <- st_read("data/concept.gpkg", "bv")
# 1854
# jointure ville code insee pour les résultats
election2022 <- read.csv("data/gros/p2022-resultats-bureaux-t1.csv", header = T, colClasses = "character")
# renommer la 1e colonne si nécessaire
names(election2022)[1] <- c("insee")
```




```{r}
# Pb pointe à pitre (61 obs)
Martinique <- election2022[grep("Fort-de", election2022$Commune),]
# extraction
election2022Sel <- election2022 [election2022$insee %in% ville$insee,]
# 2213 lg
length(unique(election2022Sel$insee))
# 45 - 7 arrondissements + Fort de France
(pb <- setdiff(ville$insee, election2022Sel$insee))
Paris <- election2022 [election2022$insee == "75056",]
Paris$CodeBdeVote
# 4 chiffres les 2 premiers l'arr les deux derniers le bureau
Paris$arr <- substring(Paris$CodeBdeVote,  1 ,2)
Paris$insee <- paste0("751", Paris$arr)
# filetre sur les arrondissements
Paris <- Paris [Paris$insee %in% pb,]
unique(Paris$insee)
```

Total

```{r}
election2022Sel
Martinique$insee <- "97209"
Martinique <- Martinique [,-55]
# suppression de la colonne arr
names(Paris)
Paris <- Paris [, -55]
election <- rbind(election2022Sel, Martinique, Paris)
write.csv(election,"data/election2022.csv", fileEncoding = "UTF-8")
```

2785 lg ou bv (1759 bv)


```{r}
bv$insee
election <- election [election$insee != "75056",]
write.csv(election, "data/election2022.csv", fileEncoding = "UTF-8")
```

1885


### combien de bv dans le fichier bv ? 17 et 18

cas particuliers à explorer (pour 2024)

```{r}
pb <- election2022 [election2022$INSEE_COM %in% c('13055', '69123'),]
lyon <- pb [pb$Libellé.de.la.commune == 'Lyon',]
lyon <- lyon [lyon$Code.du.b.vote %in% c(101:117),]
lyon$INSEE_COM <- '69381'
mars <- pb [pb$Libellé.de.la.commune == 'Marseille',]
mars <- mars [mars$Code.du.b.vote %in% nomBureauMars,]
mars$INSEE_COM <- '13201'
election2022Sel <- rbind(election2022Sel, lyon, mars)
```



pb de la décimale


```{r}
election2022 <- read.csv("data/election2022.csv", 
                         fileEncoding = "UTF-8", dec =",")
str(election2022$CodeBdeVote)
write.csv(election2022,"data/election2022.csv", fileEncoding = "UTF-8")
```



Ce fichier sera joint à celui des bureaux de vote.

# Carreaux

Utilisation des carreaux 1 km 
On fait une base sqlite pour cours SQL par commune ? Un .gpkg suffit

Les carreaux sont ceux du lien du cours :
https://www.insee.fr/fr/statistiques/4176293?sommaire=4176305

## Les données et la projection


On utilise selon l'humeur le gpkg ou le shp (en fonction des ordis)

```{r}
car <- st_read("data/gros/Filosofi2015_carreaux_1000m_metropole.gpkg")
st_layers("data/concept.gpkg")
car <- st_read("data/gros/Filosofi2015_carreaux_1000m_metropole.shp")
# 375 en 2154

```

Pb de la projection epsg 5490

```{r}
summary(st_area(carMartinique)/1000000)
carMartinique2154 <- st_transform(carMartinique, 2154)
summary(st_area(carMartinique2154)/1000000)
```

Donc rester dans la projection pour faire les stats. Les
carreaux sont faits pour faire 1km en Martinique

```{r}
ville <- st_read("data/concept.gpkg", "ville")
str(ville)
# nettoyage fichier
names(ville) [2] <- "nom"
ville <- ville [,-3]
# attention test sur 19e / Perpignan et Champs sur marne / Fort de France
# on a recupere le fichier du moodle...
st_crs(car)
summary(st_area(car))
car4326 <- st_transform(car, 4326)
summary(st_area(car4326))
# pas de différence quasiment
st_crs(ville)
ville <- st_transform(ville, 2154)

```

## Intersection bv carreaux générale

pas Martinique

```{r}
bv <- st_read("data/concept.gpkg", "bv")
# 1715
car <- st_read("data/gros/Filosofi2015_carreaux_1000m_metropole.gpkg")
car$id <- rownames(car)
st_crs(car)
st_crs(bv)
# ce n'est pas les carreaux qu'on transforme puisque base 1 km en 2154
bv <- st_transform(car, 2154)
# opération lente et resultat lourd
inter <- st_intersection(car, bv)
st_write(inter, "data/gros/concept.gpkg", "interBVCarreaux", delete_layer = T)
```

## Intersection carreaux ville

```{r}
# filtre sur une seule colonne
inter <- st_intersection(car [, c("Ind")], ville)
# ou pas (il faut se décider !)
inter <- st_intersection (car, ville)
inter
st_write(inter, "data/concept.gpkg", "interCar1kmVille", delete_layer = T)
# 1744 carreaux
str(inter)
mf_map(inter)
```

### Le coefficient

En % combien vaut l'aire du carré découpé ?
On modifie les données en conséquence avant l'enregistrement
et on ne travaille que sur la densité

### prorata du carreau

```{r}
inter$coeff <- round(st_area(inter)/10000,0)
# on ramène en base 100
summary(inter$coeff)
```

Application du coeff aux valeurs

```{r}
names(inter)
str(inter)
library(units)
inter$coeff <- drop_units(inter$coeff)
interProrata <- inter$coeff * inter [, c(2:31), dropgeom = T]
prorata <-  function(variable) {inter$coeff * variable}
lapply(inter [,c(2:31), drop = T], prorata)
```



## Export ville par ville

export des carrés ville par ville pour inclure Fort de France


```{r}
insee <- ville$insee
nb <- NULL
for (i in insee) {
  tmp <- inter [inter$insee == i,]
  id <- c(i, length(tmp$Id_carr1km))
  nb <- rbind(nb, id)
  st_write(tmp,"data/carreaux.gpkg", paste0("car_", i), delete_layer = T)
}
# verif
nb  <- data.frame(nb)
nb [nb$X2 == 0,]
# c'est Fort de France, bien sûr !
```

Fort de France


```{r}
carMartinique <- st_read("data/gros/Filosofi2015_carreaux_1000m_reg02.gpkg")
st_crs(carMartinique)
fDf <- ville [ville$insee == 97209,]
st_crs(fDf)
fDf <- st_transform(fDf, 5490)
interMartinique <- st_intersection (carMartinique [,"Ind"], fDf)
mf_map(interMartinique)
summary(st_area(inter)/10000000)
mf_map(interMartinique)
# verif du 1km pour les carreaux
summary(st_area(interMartinique)/1000000)
st_write(interMartinique, "data/carreaux.gpkg", "car_97209", delete_layer = T)
>>>>>>> 07c4a6d6280333b971f3c773ab3098756b537a92
```

# groupe et TD


```{r}
joint$groupe <- toupper(joint$nom.sexy.pour.votre.groupe..sera.utilisé.comme.titre.de.la.story.map.)
table(joint$groupe)
joint <- merge(base [, c("insee")], joint [, c("groupe", "insee", "prénom")], by = "insee") 
joint
file.remove("data/groupe.geojson")
st_write(joint , "data/groupe.geojson", append = F)
```

Les données et les problématiques

```{r}
etudiant$sources.du.données.du.cours..data.gouv..iris.résultats.des.votes.filosofi.limites.administratives.bv..lieu.et.contours..vf
etudiant$esquisse.de.votre.problématique..individuelle.
etudiant$repérer.d.autres.sources.de.données.que.celles.du.cours
```


