---
title: "Introduction"
output:
  html_document:
    number_sections: yes
    toc: yes
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval  = TRUE)
knitr::opts_chunk$set(echo  = TRUE)
knitr::opts_chunk$set(warning  = FALSE)
``` 


# Intitulé et déroulé du cours

*"L4GEOMAT - TD - Bases conceptuelles de la géomatique"*

```{r}
data <- read.csv("data/derouleGeomatique.csv", fileEncoding = "UTF-8")
knitr::kable(data [,-1])
```


# La donnée opendata

Définir l'opendata

## résultats élections

Au départ les données sur les élections disponibles

https://www.data.gouv.fr/fr/pages/donnees-des-elections/

## bureaux de vote

intérêt de la maille du bureau de vote

Chercher *REU* au niveau de la zone de recherche de data.gouv, quelles perspectives pour les chercheurs ?

regarder les 4 réponses. Laquelle est la plus intéressante

### Cartographies bureaux de vote


https://makinacorpus.github.io/bureaux-de-vote-reconstruction/#12.39/48.91021/2.48385

https://demo-terravisu.solutions-territoriales.fr/visualiser/elections#map=14.27/48.9005/2.46921&layers=a0c5903b79811fda82ef73b9dca9aacc


# La donnée à utiliser

## Les choix des étudiants

```{r}
villes <- read.csv("data/etudiantGeomatique.csv", fileEncoding = "UTF-8")
villes <- unique(villes$code.INSEE)
# il manque le 13e car 2 étudiants avaient choisi la même ville
villes <- c(villes, 75113, 93010,33325,33100,33382)
```

11 communes + Bondy

Rajouter Plassac, Cars, Saint Chrystophyde de blaye;33325,33100,33382

Donc, on attend 15 communes en tout


## Les bureaux de vote

### Données avec rues osm / frédéric rodrigo

https://www.data.gouv.fr/fr/users/frederic-rodrigo/

```{r}
library(sf)
bv <- st_read("data/gros/bureau-de-vote-insee-reu-openstreetmap.gpkg")
bondy <- bv [bv$insee == '93010',]
st_write(bondy,"data/geomatique_bvBondy.geojson", append = F)
#st_write(bv,"data/gros/bv.geojson", append = F)
st_coordinates(bondy)
```

extraction des communes du fichier F. Rodrigo



```{r}
bvSel <- bv [bv$insee %in% villes,]
length(unique(bvSel$insee))
# 13, manque les 2 arrondissements 
# pb des arrondissements parisiens
paris <- (bv [grep('^75109|^75113', bv$bureau),])
bvSel <- rbind(bvSel, paris)
(unique(substring(bvSel$bureau,1,5)))
# Normalement 15-1 puisque code INSEE pour paris
length(unique(bvSel$insee))
substring(bvSel$bureau,1,5)
bvSel$insee[grep ("^33100",bvSel$insee)]
```

pour les communes 75056 paris et pour les bv NA pour 2 communes du 33... donc 14, mais c'est
ok pour 15

```{r}
str(bvSel)
bvSel <- bvSel [,-4]
st_write(bvSel , "data/bv.geojson", append = F)
```


vérification doublons


```{r}
bvSelDoublon <- bvSel[!duplicated(bvSel),]
bvSelDoublon <- bvSel [unique(bvSel$bureau),]
```



```{r}
library(mapsf)
fond <- st_read("data/gros/DEPARTEMENT_CARTO.shp")
dpt = 33
carto <- function(dpt){
  fondSel <- fond [fond$INSEE_DEP == dpt,]
  bvSel2 <- bvSel [substring (bvSel$insee,1,2) == dpt,]
  # pour les étiquettes
  commune <- aggregate(bvSel2, by = list(bvSel2$nom), length)
  # pb géométries
  commune <- st_cast(commune, "MULTILINESTRING")
  commune <- st_centroid(commune)
  commune <- aggregate(commune, by = list(commune$Group.1), length)
  png(paste0("img/coursGeomatique_", fondSel$INSEE_DEP,".png"))
  mf_init(fondSel)
  mf_map(fond, add = T, col = "antiquewhite", border= "white")
  mf_map(bvSel, add = T, col = "red", border=NA)
  mf_label(commune, var = "Group.1", halo = T)
  mf_layout(paste0("Choix des communes cours géomatique 2024 - dpt ", fondSel$INSEE_DEP), credits = "IGN")
  dev.off()
}
dpt <- unique(substring(villes, 1,2))
res <- lapply(dpt, carto)
```


zoom sur ile de france et gironde
```{r}
fondParis<- fond [fond$INSEE_REG == 11,] 
fondGironde <- fond [fond$INSEE_DEP == 33,]
```





enregistrement par dpt

```{r}
for (d in dpt){
  print(d)
  data <- bv [substring(bv$insee,1,2) == d,]
  st_write(data, paste0("data/geomatique_dpt",d, ".geojson"), append = FALSE)
}
```




### Autre donnée : celle d'opendata

La donnée est beaucoup plus lourde à traiter. Mais on essaie de voir si les frontières sont
semblables sur Bondy.

De plus, essai d'utiliser le format pmtiles pas probant

pb format pmtiles

pour trouver le nom de la couche
https://protomaps.github.io/PMTiles/?url=https%3A%2F%2Fwww.data.gouv.fr%2Ffr%2Fdatasets%2Fr%2F53b31b93-82bf-4859-ada9-d00b91952f95#map=2.92/18.53/-2.99


```{r}
library(leaflet)
library(leafem)
#https://www.data.gouv.fr/fr/datasets/r/53b31b93-82bf-4859-ada9-d00b91952f95
#https://files.data.gouv.fr/pmtiles/reu-france-entiere-latest.pmtiles
url_bv <- "https://files.data.gouv.fr/pmtiles/reu-france-entiere-latest.pmtiles"
couche <- "repertoire-unique-electoral-polygons"
leaflet() %>% 
  addTiles() %>% 
  addPMPolygons(
    url = url_bv,
    style = paintRules(layer = couche, color = "pink", width = 3)
  ) %>% 
  setView(2.4, 49.89,7)
```

pas d'affichage de la couche, peut-être pb mémoire. on utilise le .geojson

```{r}
bvOpenData <- st_read("data/gros/contours-france-entiere-latest.geojson")
bvOpenData [grep("^75113", bvOpenData$id_bv),]
```


Pour le bvOpendata, un seul champs id_bv dont la 1e partie contient le code insee


```{r}
library(mapsf)
# fonction pour générer un fichier par bureau
chercherBureaux <- function(codeInsee){
  tmp <- (bvOpenData [grep(paste0("^",codeInsee), bvOpenData$id_bv),])
  st_write(tmp, paste0("data/opendata_", codeInsee,".geojson"), append = FALSE)
}
chercherBureaux(75113)
res <- lapply(villes, chercherBureaux)
# constitution fichier total
res2 <- NULL
tmp <- NULL
for (v in villes) {
  print(v)
  tmp <- (bvOpenData [grep(paste0("^",v), bvOpenData$id_bv),])
  res2 <- rbind(res2, tmp)
}
st_write(res, "data/opendata_bv.geojson")
library(mapsf)
```

carto les 2 bondy

```{r}
bondyOpen <- res [[12]]
mf_map(bondyOpen)
bondy <- st_read("data/geomatique_bvBondy.geojson")
mf_map(bondy, add = T, col = NA, border = "red")
bondy$num <- gsub("93010_", "", bondy$bureau)
mf_label(bondy, var = "num" , halo = T)
# zoom
mf_init(bondy [bondy$num == 1,])
mf_map(bondyOpen, add = T, col = NA, border = "green")
mf_map(bondy, add = T, col = NA, border = "red")
bondy$num <- gsub("93010_", "", bondy$bureau)
mf_layout("Comparaison fichiers pour Bondy", "data.gouv / F. Rodrigo")
```




```{r}

st_write(bvSel, "data/bv.geojson", append = FALSE)
unique(bvSel$insee)
```


# Intersection

Objectif : chercher les bureaux de vote qui ne sont pas ds les zones.



```{r}
bureau <- read.csv("data/table-bv-reu.csv")
bureau <- bureau [bureau$code_commune == '93010',]
str <- paste(villes,",")
str2 <- sapply(str, paste0)
bureau <- bureau [bureau$code_commune %in% str2,]
```


grrr... on passe par OSM

```{r}
library(sf)
library(mapsf)
bureau <- st_read("data/bureauxBondy.geojson")
bureau <- bureau [!is.na(bureau$polling_station.ref),]
bureau <- st_centroid(bureau)
mf_map(bureau)
zone <- st_read("data/bvBondy.geojson")
mf_map(zone, add = T, col = NA)
zone$num <- gsub("93010_", "", zone$bureau)
st_write (zone [,"num"], "data/bondyZone.geojson")
st_write(bureau [, "polling_station.ref"], "data/bondyBureauLoc.geojson" )
```


```{r}
inter <- st_intersection(bureau[,"polling_station.ref"], zone [, "num"])
knitr::kable(inter [, c("polling_station.ref", "num")])
inter$test <- ifelse(inter$polling_station.ref == inter$num, "TRUE", "FALSE")
table(inter$test)
```

On observe que 

# Présentation rapide (vous êtes nombreux !)

## Qui sont les étudiants ?






```{r}
etudiant <-  read.csv("data/etudiantGeomatique.csv", fileEncoding = "UTF-8")
names(etudiant)
png("img/quisontils.png", width = 8000, height = 5000, res=600)
#par(mar = c(2,16,2,4))
par(mfrow = c(1,3))
for (i in 2:4){
  par(mar=c(1, 12, 2, 2))
  barplot(sort(table(etudiant [,i])), border = NA,
          horiz = T, las = 2, cex.names = 0.8, 
          main = names (etudiant) [i])
}
dev.off()
```


![](img/quisontils.png)


## Présence et rendu des devoirs : chiffres clés

### Effectif et cours

```{r, eval=TRUE}
fic <- list.files("data/", pattern = "^cours")
fic
# on recherche le fichier le plus haut
nb <- max(as.integer(substring(fic, 6,7)))
tmp <- NULL
tab <- NULL
i <-  1
for (i in 1:nb) {
  print(i)
  nomFic <- paste0("data/cours", i, ".csv")
  data <- read.csv(nomFic, fileEncoding = "UTF-8")
  data <- data [data [,2] == "oui",]
  tmp <- table(data$groupe)
  tab <- rbind(tab , tmp)
}
tab
row.names(tab) <- paste0("cours ",seq(1,nb, by = 1))
paste0("cours ",seq(1,nb, by = 1))
knitr::kable(tab)
# Graphique
p <- barplot(tab, beside = T, main = "nombre d'étudiants par groupe et par cours", xlab = "groupe", ylab = "nb", col = terrain.colors(nb) 
        , border = NA, legend =  F)

```





### Les rendus d'exercices



```{r}
rendu <- c(56,59, 56, 45,58,49)
titre <- c("distribution", "univarié", "contingence", "khi2", "regression", "1er script")
par(mar = c(8,6,6,6))
p <- barplot(rendu, names = titre, cex.names = 0.8, las = 2, main = "rendu devoirs (effectif 75 étudiants environ)", border = NA)
text(p, y = rendu - 1, labels = rendu )
```


#### Les notes des exercices


- Le critère externe : des points faciles ?

le nom du fichier
le temps du rendu (avant la limite)

- Distribution des totaux

```{r, eval=T}
res <- read.csv("data/exo.csv",  na.strings = '-', fileEncoding = "UTF-8")
names(res)
res <- res [, c(2:5,1,6)]
# recodage : si note 2, alors note1 = 0 si NA
res$X1_Univarié.1 [is.na(res$X1_Univarié.1 )& !is.na(res$X2_Univarié.2)] <- 0
res$X1_Univarié.1 [ is.na(res$X2_Univarié.2)] <- NA
# graphique
par(mfrow= c(2,3))
for (i in (1:length(res))){
  p <-barplot(table(res[,i]), main = names(res)[i])
}
```




## Notes finales



```{r, eval=FALSE}
note <- read.csv("data/noteFinales.csv", fileEncoding = "UTF-8", na.strings = c("EN ATTENTE", "NA","-"), dec = ",")
summary(note)
png("img/noteFin.png")
hist(note$NOTE.FINALE, main = "Etalement note finale - 64 obs", freq = T, border = NA)
abline(v = mean(note$NOTE.FINALE, na.rm = T),  col = "red")
abline(v = median(note$NOTE.FINALE, na.rm=T), col = "blue")
dev.off()
```

![](img/noteFin.png)



