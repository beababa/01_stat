---
title: "Préparation partiel"
output:
  html_document:
    number_sections: yes
    toc: yes
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval  = TRUE)
knitr::opts_chunk$set(echo  = TRUE)
knitr::opts_chunk$set(warning  = FALSE)
``` 




Plusieurs difficultés possibles en fonction de votre état d'avancement


# Ouverture et lecture de fichiers

Ces exercices permettent de vous familiariser avec différents types d'interface.

Votre objectif restent de filtrer au maximum les données et de télécharger un .csv pour l'ouvrir
directement sous R.

Évitez de passer par un tableur...


## Logements vacants

Attention il faut faire :


Pour avoir accès à la plateforme de la donnée. On retrouve alors la même interface que pour 
les statistiques locales de l'Insee vue pour le DM.



```{r}
logvac <- read.csv2("data/LOGVAC.csv", skip = 3)
# séparateur ";" et 2 lignes de titre
summary(logvac)
# vérification du type de la variable
```

## Eurostat

Passer par 



```{r}
eurostat <- read.csv("data/eurostat.csv")
summary(eurostat)
# filtre sur colonnes geo et OBS_VALUE
eurostat <- eurostat [,c(6,8)]
head(eurostat)
```

## Valeurs foncières data.gouv

Passer par 


```{r}
dvf <- read.csv("data/gros/dvf.csv", dec = ".")
dvf <- dvf [dvf$nom_commune == 'Bondy', c("id_parcelle","valeur_fonciere")]
summary(dvf)
# on filtre sur la commune et comme colonne l'identifiant parcelle et la valeur foncière
# on force le champs valeur foncière en numérique ce qui crée des NA que l'on supprime
dvf$valeur_fonciere <- as.numeric(dvf$valeur_fonciere)
dvf <- na.omit(dvf)
```


5 lignes supprimées sur 1266 = c'est minime

## Origine et taille de chacune des données.

Dans chacun des 3 cas, il s'agit de sources fiables.

La taille des dvf est beaucoup plus importante que les 2 autres sources (problème de téléchargement possible en salle de cours)


```{r}
data <- read.csv("data/donnees_cours13.csv", fileEncoding = "UTF-8")
knitr::kable(data)
```



# Univarié


## Logements vacants

```{r}
hist(logvac$Nombre.de.logements.vacants.2022)
head(logvac [order(logvac$Nombre.de.logements.vacants.2022, decreasing = T),])
# Exclure Paris
logvac <- logvac [logvac$Code != 75056,]
# avec un peu de mise en forme
hist(logvac$Nombre.de.logements.vacants.2022/1000, main = "Répartition du nb de logements vacants\nIle de France", xlab = "Montants (milliers de logements)", ylab = "Nb de communes du 93", border = NA, col = "cadetblue")
# affichage médiane / moyenne
abline(v=mean(logvac$Nombre.de.logements.vacants.2022, na.rm = T)/1000, col="red")
abline (v=median(logvac$Nombre.de.logements.vacants.2022, na.rm = T)/1000, col="blue")
```

## Inflation

```{r}
hist(eurostat$OBS_VALUE)
# il y a une valeur extrême
summary(eurostat)
head(eurostat [order(eurostat$OBS_VALUE, decreasing = T),])
# c'est la Turquie, si on l'enlève
eurostat <- eurostat [eurostat$geo != 'Turquie',]
```


```{r}
hist(eurostat$OBS_VALUE)
# avec un peu de mise en forme
hist(eurostat$OBS_VALUE, main = "Répartition des taux d'inflation 2024\nEurope", xlab = "Tx de variation moyen sur 2024 (%)", ylab = "Nb de pays européens", border = NA, col = "wheat")
# affichage médiane / moyenne
abline(v=mean(eurostat$OBS_VALUE), col="red")
abline (v=median(eurostat$OBS_VALUE), col="blue")
```


## Valeurs foncières

```{r}
options(scipen = 100)
summary(dvf$valeur_fonciere/1000)
hist(dvf$valeur_fonciere)
```


```{r}
hist(dvf$valeur_fonciere/1000, main = "Répartition du montant des transactions immobilières\nBondy", xlab = "Montant", ylab = "Nb de transactions", border = NA, col = "wheat")
# affichage médiane / moyenne
abline(v=mean(dvf$valeur_fonciere/1000), col="red")
abline (v=median(dvf$valeur_fonciere/1000), col="blue")
```




## Courte analyse

```{r}
data <- read.csv("data/analyseCours13.csv")
knitr::kable(data)
```


# Bivariée

## Khi2 : logements vacants par dpt

#### Tableau de contingence

```{r}
hist(logvac$Nombre.de.logements.vacants.2022)
logvac$categorie <- cut(logvac$Nombre.de.logements.vacants.2022, breaks = c(0,500,750,5000))
table(logvac$categorie)
```



```{r}
logvac$dpt <- substring(logvac$Code,1,2)
tab <- table(logvac$dpt,logvac$categorie)
tab
```


#### Khi2

Pas de chiffre < 5, on peut faire un khi2


```{r}
test <- chisq.test(tab)
test
```

La p-value est réduite donc l'hypothèse nulle est rejetée, il y a bien un lien entre les dpts et le
nombre de logements vacants en Ile de France.

Il paraît d'ailleurs évident au vu du tableau de contingence qu'il y a moins de logements vacants dans le
77 78, 91 et 95 que dans le 92,93,94.

Mais, encore une fois, le nombre de logements vacants doit être dépendant de la taille des villes.

## Régression : tx d'inflation et chomage (milliers de personnes)

### Constitution de la base : inflation et chômage

```{r}
chomage <- read.csv("data/chomage.csv")
chomage <- chomage [, c("geo","OBS_VALUE")]
jointure <- merge (eurostat, chomage, by = "geo")
names(jointure) <- c("pays", "inflation", "chomage")
hist(jointure$chomage)
filtre <- jointure  [jointure$chomage < 2000,]
hist(filtre$chomage)
filtre <- jointure  [jointure$chomage < 500,]
```

On a effectué un double filtre de manière à avoir une donnée de taille comparable.


### Modèle

```{r}
lm <- lm(filtre$chomage~filtre$inflation)
plot(filtre$inflation, filtre$chomage, xlab="variable explicative\ninflation", ylab= "à expliquer : chômage")
abline(lm, lty =2, lwd = 1, col = "red")
text(filtre$inflation, filtre$chomage,labels = filtre$pays
      , cex=0.6, pos = 2)
```



```{r}
cor(filtre [,c(2,3)])
```


Il apparaît qu'il n'y a pas de relation entre tx d'inflation et chomage.
Le filtre a sélectionné des pays de taille comparable mais leur position est trop dispersée.
Apparaît cependant des groupes qui pourraient éventuellement permettre d'établir
une division spatiale des pays européens.



## Variance : logements vacants par dpt


```{r}
boxplot(logvac$Nombre.de.logements.vacants.2022~logvac$dpt)
names(logvac)[3] <- "nb"
modele <- lm (nb ~ dpt, data = logvac)
anova(modele)
```


Comme le montre le résultat de l'ANOVA, il y a une forte différenciation entre les
départements d'île de France autour des logements vacants.


# ACP : déplacements domicile travail

## Travail préparatoire sur le fichier avant l'ACP : le fichier est trop gros

Préparation du fichier final, on filtre sur les dpts utilisés en cours

```{r, eval = FALSE}
# très gros fichier, on filtre sur les dpts 
dep <- read.csv2("data/gros/depl_dom_trav_co2_2022.csv", na.strings = "NA")
lieu <- c(lieu, "06088")
filtre <- dep [dep$LIEU_RESID %in% lieu,]
write.csv(filtre,"data/gros/deplacement.csv", fileEncoding = "UTF-8" )
```

On coupe le fichier par dpt pour que les étudiants puissent l'ouvrir


```{r, eval=FALSE}
dep <- read.csv("data/gros/deplacement.csv", fileEncoding = "UTF-8")
names (dep)
dpt <- names(table(dep$DEP_RESID))
for (d in dpt){
  tmp <- dep [dep$DEP_RESID == d,]
  write.csv(tmp, paste0("data/deplacement", d, ".csv"), fileEncoding = "UTF-8")
}
```

## Au choix on traite d'un département



```{r}
dep <- read.csv("data/gros/deplacement93.csv", fileEncoding = "UTF-8")
```


On fait le choix des numériques DIST_HEBDO CO2_HEBDO DUREE CARBU_HEBDO avec l'idée 
que toutes les valeurs sont corrélées

```{r}
dep <- dep [, c("DIST_HEBDO", "CO2_HEBDO", "DUREE", "CARBU_HEBDO")]
dep <- na.omit(dep)
# attention bcp de na on passe de  50 M à 16 M
```



```{r}
summary(dep)
# ordres de grandeur
round(cor(dep),1)
# relations (numériques)
pairs(dep)
# relations (graphiques)
```

On voit que si CARBU et HEBDO sont totalement liées, distance et durée vers les
valeurs hautes sont plus diversifiées


```{r}

```





On sélectionne  les individus à la durée la plus longue

```{r}
hist(dep$DUREE)
dep <- dep [dep$DUREE > 40,]
```

L'ACP est normée car les unités sont différentes

```{r}
res <- prcomp(dep, scale. = T)
biplot(res, main= "Résultat d'une ACP normée", col= c("black", "chartreuse"), cex = 0.5)
```

Il y a beaucoup d'individus qui sont loin des axes. Il faut examiner leur caractéristiques.

```{r}
remarquable <- c(48327, 48421, 48324)
dep$id <- rownames(dep)
dep [dep$id %in% remarquable,]
```

On peut voit donc avec ces 3 cas que pour une durée similaire, les consommations de carburant et l'émission de CO2 vont du simple au double. Cela dépend du moyen de transport utilisé, à noter également que la distance est plus faible pour celui qui doit utiliser un transport en commun.


