---
title: "Multivariées : démarche explicative"
output:
  html_document:
    number_sections: yes
    toc: yes
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval  = TRUE)
knitr::opts_chunk$set(echo  = TRUE)
knitr::opts_chunk$set(warning  = FALSE)
``` 


La régression multiple est une démarche explicative.


# Préparation de la donnée

Il s'agit de réfléchir à de nombreux X pour expliquer un seul Y

Dans notre exemple, nous reprenons comme 

- facteur à expliquer (Y) = la population d'une ville (que nous assimilons à la taille d'une ville)

- facteurs explicatifs (X) = les frais de personnel, les dépenses d'équipement, les emprunts, et les ventes de biens et service

Le choix des variables est très important, il ne faut pas qu'elles soient corrélées entre elles, ce qui, sur nos données, est assez difficile puisqu'il s'agit de comptes équilibrés.

... Mais avoir une situation où une seule variable est expliquée par plusieurs autres reste une gageure.

exemples utilisés dans l'ouvrage de référence, le chadule :

- précipitation par longitude et latitude

- vote pour LE PEN et étrangers, délinquants, chômeurs, population urbaine



```{r}
data <- read.csv2("data/dataRegressionMultiple.csv", fileEncoding = "UTF-8", dec = ".")
names(data)
# filtre colonne
data <- data [, c(27,16, 24,25,26,28)]
names(data)
names(data) <- c("pop", "commune", "agregat", "montant", "montantM", "montantTX")
table(data$agregat)
```


## Exercice de cours

Utiliser l'aide F1 pour voir les options utiles de *read.csv2*

Analyse des réponses données par les étudiants :

on retrouve :

- dec, sep, fileEncoding (peu utilisé avec les données de l'Ofgl)

mais aussi :

- header, FileEncoding, row.names, skip

Un exemple pour le row.names

```{r}
tmp <- read.csv("data/communeEtudiant.csv", row.names = 2)
head(tmp)
```


Attention

- getwd(), names() sont des *fonctions* et non des paramètres


# Transformation du tableau

Il s'agit d'abord de simplifier les chiffres, puis de faire un choix sur le montant et
enfin d'éclater les agrégats pour obtenir une colonne pour chaque agrégat.

Le travail sur la préparation du tableau est donc essentiel et représente une grosse partie de l'étude.


## Simplifier les chiffres


Concernant la population de la ville, l'ordre de grandeurs se voit au travers de l'histogramme

```{r}
hist(data$pop)
```


Afin d'avoir des chiffres plus faciles à appréhender, on raisonne en dizaine de milliers pour la population.


Mais, il ne faudra pas oublier de le rappeler à chaque graphique.

```{r}
data$pop <-  data$pop/10000
hist(data$pop, main = "Répartition population villes 93", xlab = "population (en dizaine de milliers)", ylab = "nb de communes")
```


Remarque : ordres de grandeur pour les données étudiants

```{r}
dataEtudiant <- read.csv("data/communeEtudiant.csv")
dpt <- unique(dataEtudiant$departement)
# 28 dpt choisis
# on récupère la donnée sur statistiques locale de la population par dpt
pop <- read.csv2("data/popDep.csv", na.strings = "N/A - résultat non disponible")
# attention au pb du NA
pop <- pop [pop$Code %in% dpt,]
# 28 dpt avec pop
hist(pop$Population.municipale.2022, col = "cadetblue2", border = NA, main = "Ordres de grandeur dpt choisis par les étudiants", xlab = "pop dpt", ylab= "nb de dpt")
hist(pop$Population.municipale.2022/100000, col = "cadetblue2", border = NA, main = "Ordres de grandeur dpt choisis par les étudiants", xlab = "pop dpt (en centaine de milliers)", ylab= "nb de dpt")
```

Cependant, dans les réponses étudiant à la question de l'ordre de grandeur de 10 000 et inférieurs. 



2 exercices à faire :


- comment utiliser l'aide F1 pour trouver les options nécessaires pour présenter le 
graphique


Remarquer notamment : main (titre), xlab (titre axe X), ylab (titre axe Y)

- quelle est l'analyse de ce graphique ?

Il y a quelques très petites villes et grosses villes mais la majorité des villes
sont entre 500 000 et 1,5 million.


```{r}
data$popArr <- round(data$pop,0)
unique(data [order(data$popArr), c(2,7)])
```

exercice :

- A quoi servent les fonctions *round*, *unique* et *order* ?

réponse :

Les fonctions servent à arrondir les chiffres, à supprimer les doublons et à classer
par ordre croissant


L'option qui permet de classer en ordre décroissant est decreasing=TRUE (consulter l'aide F1 pour le voir)


## Montant relatif ou montant absolu ?

On choisit d'utiliser le montant en millions puisque le but de l'exercice est d'avoir des variables indépendantes.


```{r}
plot(data$montantTX, data$pop, xlab = "Montant / hbt", ylab = "population (en dizaine de milliers)", main = "Utilisation du montant par habitant")
plot(data$montantM, data$pop, xlab = "Montant (millions)", ylab = "population (en dizaine de milliers)")
```

exercice : que permettent de voir ces deux graphiques ?

La relation entre montant en millions et population est plus claire que celle existant
entre montant par hbt et population.

## Constitution de la base

Les agregats sont sur une seule colonne, il faut créer une colonne par agrégat.

Sous le tableur, on ferait des copier-coller, ou du tcd.

Sous R, on utilise une jointure : pour chaque commune, donne moi l'élément correspondant
de l'agrégat.

On répète l'opération dans une boucle afin d'aller plus vite

```{r}
varX <- names(table(data$agregat))
fin <- unique(data [, c("commune","pop")])
# A chaque variable
for (v in varX){
  # définir une table temporaire uniquement pour la variable choisie
  tmp <- data [data$agregat==v, c("commune","montantM")]
  # nommer les sommes sélectionnées du nom de la variable
  names(tmp) [2] <- v
  jointure <- merge(tmp, fin, by = "commune")
  # Récupérer le tableau pour le tableau final
  fin <- jointure
}
fin
# anciens noms
names(fin)  [2:5]
# simplification des noms
names(fin) [2:5] <- c("vente", "personnel", "emprunt", "equipement")
```


Enregistrement du tableau de données mis en forme

```{r}
write.csv(fin, "data/baseMultivarie.csv", fileEncoding = "UTF-8")
```


Dans l'exercice moodle, à la question "A quoi sert une boucle", un étudiant a 
répondu 

*à concevoir la base de données et à avoir une colonne par agrégat avec ses valeurs*

Ce qui correspond à la réponse précise sur la boucle


## Base pour les étudiants

Afin de fournir une donnée propre pour le multivarié, voici l'extraction pour les 28 dpt
recensés.

```{r}
data <- read.csv2("data/gros/baseEtudiantMultivarie.csv", dec = ".")
dpt <- read.csv("data/communeEtudiant.csv")
dpt <- unique(dpt$departement)
# filtre colonne
data <- data [, c(5,27,16, 24,26)]
names(data)
names(data) <- c( "dpt", "pop", "commune", "agregat", "montant")
table(data$agregat)
table(data$dpt)
data <- data [data$dpt %in% dpt,]
length(unique(data$dpt))
```

On a les données pour 28 dpts

Puis on relance la boucle (avec quelques modifications)


```{r}
varX <- names(table(data$agregat))
fin <- unique(data [, c("dpt","commune","pop")])
# A chaque variable
for (v in varX){
  # définir une table temporaire uniquement pour la variable choisie
  tmp <- data [data$agregat==v, c("dpt","commune","montant")]
  # nommer les sommes sélectionnées du nom de la variable
  names(tmp) [3] <- v
  jointure <- merge(tmp, fin, by = c("dpt","commune"))
  # Récupérer le tableau pour le tableau final
  fin <- jointure
}
head(fin,5)
# anciens noms
names(fin)  [3:6]
# simplification des noms
names(fin) [3:6] <- c("personnel", "emprunt", "equipement", "etat")
write.csv(fin,"data/baseMultivarieSel.csv", row.names = F)
```


On avait au départ 33 000 enregistrements, à la fin, après le traitement, il ne reste plus "que" 8253 observations.


# Modèle de régression multiple


On utilise la base faite ci-dessus et on sélectionne son département.


## Préparation de la donnée

```{r}
data <- read.csv("data/baseMultivarieSel.csv")
data <- data [data$dpt == 93,]
head(data,5)
# on place les noms des communes comme étiquette
rownames(data) <- data$commune
# on supprime les 2 premières colonnes
data <- data [, -c(1,2)]
head(data,5)
```

On obtient ainsi un tableau dont les étiquettes sont intégrées dans l'entête des lignes
et qui ne contient que des chiffres.

```{r}
summary(data)
```



## Coefficient de correlation / détermination

### Quelques rappels et quelques calculs

Pour mémoire, la variance = moyenne du carré des écarts à la moyenne

covariance =  moyenne du produit des écarts (combien deux variables varient l'une avec l'autre)

```{r}
varPerso <- var(data$personnel)
varEmprunt <- var(data$emprunt)
# affichage scientifique ou pas
options( "scipen"=-100) 
options("scipen"= 100)
boxplot(data)
# aie, il faut diviser la population par 1000
data$pop <- data$pop / 1000
boxplot(data)
# on voit bien la petite variance et la grande variance
varPerso
varEmprunt
# calcul des écarts à la moyenne (différence et non pas distance)
prodEcart <- (data$personnel-mean(data$personnel))*(data$emprunt-mean(data$emprunt))
moyProEcart <- mean(prodEcart)
covarFormule <- cov(data$personnel,data$emprunt)
moyProEcart
covarFormule
# la différence tient à la pondération par n-1 dans le calcul de la covariance
```


le calcul de la corrélation inclue un facteur de correction (le produit des écarts types)


```{r}
moyProEcart/(sqrt(var(data$personnel))*sqrt(var(data$emprunt)))
```

### Matrices à connaître

```{r}
# matrice graphiquee
pairs(data)
# matrice de correlation
cor(data)
# matrice de détermination
# détermination R² : la donnée X explique tant de % de la population
cor(data)^2
```

On cherche :

- des variables corrélées avec la population (dernière ligne)

- des variables faiblement corrélées entre elles afin d'éviter un effet de redondance

On retire la variable emprunt qui n'apparaît pas liée à la population

Personnel, dotation de l'Etat et équipement semblent corrélées entre elles.

Cependant la correlation est la plus importante pour personnel et dotation de l'Etat.
Concernent l'équipement, c'est quasiment la même.

## Modèle : une confirmation de l'observation des matrices

```{r}
modele <- lm (formula = pop ~ equipement + personnel + etat, data = data)
```

Tout s'est-il bien déroulé ?


```{r}
modele
summary(modele)
```

On se contente de faire la lecture de la significativité du test (les étoiles) qui 
ne fait que confirmer l'analyse de la matrice de corrélation.

Le modèle est utile  car la valeur de p est modeste pour un risque de 10 %

Population et personnel ont une liaison particulièrement significative.

La manière d'interpréter la sortie des coefficients :

Si équipement et dotation de l'Etat restent constants, quand les dépenses du personnel augmente
de 8 unités, la population augmentera de 10 individus.

pop = coeff perso + coeff equipement + coeff etat




# Résidus

L'étude spatiale des résidus peut permettre de déterminer une organisation du territoire.


```{r}
hist(modele$residuals)
residus <- modele$residuals
residus <- as.data.frame(residus)
residus$name <- row.names(residus)
```



```{r, eval=F}
library(sf)
communes <- st_read("data/communes93.geojson")
communes <- communes [!is.na(communes$ref.INSEE), c("name", "ref.INSEE")]
communes$name
residus$name
# on fait une jointure entre les résidus et la géographie des communes
jointure <- merge(communes, residus, by = "name")
setdiff(residus$name, jointure$name)
summary(jointure$residus)
```




```{r, eval=FALSE}
library(mapsf)
png("img/residusCarte2.png")
mf_map(jointure, var = "residus", type="choro", breaks = c(-25, -10,0,10,15),pal = cm.colors(4), border = NA, leg_pos = c(2.31589950651953, 48.8793057936166) )
mf_label(jointure [jointure$residus > 10 | jointure$residus < - 10,], var = "name", overlap = FALSE, col= "wheat4", cex = 0.8)
mf_layout("Population  et 3 variables (personnel / dotations Etat / équipement ) : étude des résidus", credits = "OFGL, 2024")
dev.off()
```


![](img/residusCarte2.png)


Tremblay, Bobigny et Gagny s'écartent du modèle pop liées aux dépenses du personnel, dotation de l'Etat et équipement.

# Deuxième modèle

On refait l'analyse sans les dépenses d'équipement

```{r}
modele <- lm (formula = pop ~ personnel + etat, data = data)
```


## Représentation graphique

Comme il n'y a que 3 variables, on peut faire un graphique en 3D

```{r}
library(scatterplot3d)
s3d <- scatterplot3d(data$etat, data$personnel, data$pop, color = "blue")
# plan de régression
s3d$plane3d(modele)
text(s3d$xyz.convert (data  [,c(4,1,5)]), labels = rownames(data), cex = 0.4)
```


Comparer Saint Denis et Montreuil, par exemple

Globalement, cela n'est pas si lisible même à 3 dimensions.

## Résultat algébrique

Tout s'est-il bien déroulé ?


```{r}
summary(modele)
```


La significativité entre vente et population augmente si on supprime la variable
équipement.


## Cartographie

La carte des résidus ne varie pas du tout.

```{r, eval=FALSE}
hist(modele$residuals)
# permet de voir les bornes pour la cartographie
library(mapsf)
png("img/residusCarte3.png")
mf_map(jointure, var = "residus", type="choro", breaks = c(-25, -10,0,10,15), pal = cm.colors(4), border = NA, leg_pos = c(2.31589950651953, 48.8793057936166) )
mf_label( jointure [jointure$residus > 10 | jointure$residus < - 10,], var = "name", overlap = FALSE, col= "wheat4", cex = 0.8)
mf_layout("Population  et 2 variables (personnel / dotation de l'Etat) : étude des résidus", credits = "OFGL, 2024")
dev.off()
```


![](img/residusCarte2.png)![](img/residusCarte3.png)
